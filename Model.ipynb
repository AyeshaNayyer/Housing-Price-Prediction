{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SZVCb5Bivg3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import mean\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing dataset from Drive"
      ],
      "metadata": {
        "id": "XFkLmUxlvRZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLEbRxYtivhD",
        "outputId": "8982a070-cd86-4fe2-b9a4-d3f1a698a028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "# Mount Google Drive to /content/drive\n",
        "drive.mount('/content/drive')\n",
        "# Specify the path to your CSV fila\n",
        "train = '/content/drive/MyDrive/train1.csv'  # Replace with the actual path to your CSV file\n",
        "# Read the CSV file into a DataFrame\n",
        "df1 = pd.read_csv(train)\n",
        "test = '/content/drive/MyDrive/test1.csv'\n",
        "df2 = pd.read_csv(test)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iObhzLa5ivhF"
      },
      "outputs": [],
      "source": [
        "#from df1 drop sub_are\n",
        "df1 = df1.drop(columns=['sub_area'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpWtErAx1hyn",
        "outputId": "6ca04460-ac55-4367-d257-f98a18658e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Types of Columns:\n",
            "full_sq               float64\n",
            "life_sq               float64\n",
            "floor                 float64\n",
            "product_type           object\n",
            "area_m                float64\n",
            "                       ...   \n",
            "mosque_count_5000     float64\n",
            "leisure_count_5000    float64\n",
            "sport_count_5000      float64\n",
            "market_count_5000     float64\n",
            "price_doc             float64\n",
            "Length: 271, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Data Types of Columns:\")\n",
        "print(df1.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1obEyQnvivhH"
      },
      "outputs": [],
      "source": [
        "#from df2 drop sub_area and row ID\n",
        "df2 = df2.drop(columns=['sub_area', 'row ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUsr2Ke746vc"
      },
      "outputs": [],
      "source": [
        "Xtrain = df1.drop(columns=['price_doc'])\n",
        "y = df1[['price_doc']]\n",
        "Xtest = df2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vf_lMfc1SQf",
        "outputId": "925dd509-950e-4ac5-f351-eca604d46b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Categorical Columns:\n",
            "Index(['product_type', 'culture_objects_top_25', 'thermal_power_plant_raion',\n",
            "       'incineration_raion', 'oil_chemistry_raion', 'radiation_raion',\n",
            "       'railroad_terminal_raion', 'big_market_raion', 'nuclear_reactor_raion',\n",
            "       'detention_facility_raion', 'water_1line', 'big_road1_1line',\n",
            "       'railroad_1line', 'ecology'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Identify categorical columns (type object)\n",
        "cat_features = Xtrain.select_dtypes(include=['object']).columns\n",
        "print(\"\\nCategorical Columns:\")\n",
        "print(cat_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NE6YBUf1YO6",
        "outputId": "a164efab-b460-48f4-c686-2587dd3eb387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numerical Columns:\n",
            "Index(['full_sq', 'life_sq', 'floor', 'area_m', 'raion_popul',\n",
            "       'green_zone_part', 'indust_part', 'children_preschool',\n",
            "       'preschool_education_centers_raion', 'children_school',\n",
            "       ...\n",
            "       'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500',\n",
            "       'cafe_count_5000_price_4000', 'cafe_count_5000_price_high',\n",
            "       'big_church_count_5000', 'church_count_5000', 'mosque_count_5000',\n",
            "       'leisure_count_5000', 'sport_count_5000', 'market_count_5000'],\n",
            "      dtype='object', length=256)\n"
          ]
        }
      ],
      "source": [
        "# Identify numerical columns (types int8 or float64)\n",
        "num_features = Xtrain.select_dtypes(include=['int8', 'float64']).columns\n",
        "print(\"\\nNumerical Columns:\")\n",
        "print(num_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqGB4nfg6yqO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying log transformation to reduce to reduce skewness of variables"
      ],
      "metadata": {
        "id": "Vdhy2xVIvpcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWraB88I66m8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "# 2. Log Transformation\n",
        "for col in num_features:\n",
        "    if col in Xtrain.columns:\n",
        "        Xtrain[col] = Xtrain[col].apply(lambda x: 0 if x <= 0 else x)  # Handling non-positive values\n",
        "        Xtrain[col] = Xtrain[col].apply(lambda x: np.log1p(x))  # Log transformation\n",
        "        Xtest[col] = Xtest[col].apply(lambda x: 0 if x <= 0 else x)  # Handling non-positive values\n",
        "        Xtest[col] = Xtest[col].apply(lambda x: np.log1p(x))  # Log transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YYCCN4xeXHv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "for col in cat_features:\n",
        "    if col in Xtrain.columns:\n",
        "        Xtrain[col] = label_encoder.fit_transform(Xtrain[col])\n",
        "        Xtest[col] = label_encoder.fit_transform(Xtest[col])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InpD0AbVh6XJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG2y7d5Tfln5"
      },
      "outputs": [],
      "source": [
        "# 2. Numerical Feature Transformation\n",
        "scaler = MinMaxScaler()\n",
        "Xtrain[num_features] = scaler.fit_transform(Xtrain[num_features])\n",
        "Xtest[num_features] = scaler.transform(Xtest[num_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myRAdfQQocsz"
      },
      "outputs": [],
      "source": [
        "# 3. PCA Transformation\n",
        "pca = PCA(n_components=19)\n",
        "X_train_pca = pca.fit_transform(Xtrain)\n",
        "X_test_pca = pca.transform(Xtest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE_Rvlhzh-Xh"
      },
      "outputs": [],
      "source": [
        "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
        "X_train_poly = poly_features.fit_transform(X_train_pca)\n",
        "X_test_poly = poly_features.transform(X_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_poly.shape"
      ],
      "metadata": {
        "id": "A_Ue-D7J7Q0V",
        "outputId": "76377dee-cf89-4a74-e52f-e7e98935a05c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(181507, 1539)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model with opitimized features"
      ],
      "metadata": {
        "id": "htMfkb4Dv9Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zCrhMfcmy0EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = lgb.Dataset(X_train_poly, label=y)\n",
        "test_data = lgb.Dataset(X_test_poly)\n"
      ],
      "metadata": {
        "id": "jcmmsaAGy7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFABwsmKiRYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29bea4f1-3944-450b-f3ec-b6243f36d122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: importance_type\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Unknown parameter: importance_type\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Unknown parameter: importance_type\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 13.248442 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 392445\n",
            "[LightGBM] [Info] Number of data points in the train set: 181507, number of used features: 1539\n",
            "[LightGBM] [Info] Start training from score 14751285.292256\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "      'metric': 'l2',\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': -1,\n",
        "    'learning_rate': 0.05,\n",
        "    'n_estimators': 100,\n",
        "      'feature_fraction': 0.9,\n",
        "    'subsample_for_bin': 200000,\n",
        "    'objective': 'regression',\n",
        "    'min_split_gain': 0.0,\n",
        "    'min_child_weight': 0.001,\n",
        "    'min_child_samples': 20,\n",
        "    'subsample': 1.0,\n",
        "    'subsample_freq': 0,\n",
        "    'colsample_bytree': 1.0,\n",
        "    'reg_alpha': 0.0,\n",
        "    'reg_lambda': 0.0,\n",
        "    'random_state': 42,\n",
        "    'importance_type': 'split'\n",
        "}\n",
        "# Train the model\n",
        "num_round = 100\n",
        "bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bst.predict(X_test_poly, num_iteration=bst.best_iteration)"
      ],
      "metadata": {
        "id": "gOC7lSHZzUQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNFIQNVzAbbn",
        "outputId": "a153574c-8948-4a47-fcc8-ee8d7889ed52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77789,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking predicted output against output in test file"
      ],
      "metadata": {
        "id": "k2JUq3NgwJBA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvazY-kEar3R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load additional data\n",
        "additional_data = pd.read_csv('/content/drive/MyDrive/test1.csv')\n",
        "\n",
        "# Create a DataFrame with 'row ID' and predicted values\n",
        "predicted_df = additional_data[['row ID']].copy()\n",
        "predicted_df['price_doc'] = y_pred\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "predicted_df.to_csv('predictions28.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}